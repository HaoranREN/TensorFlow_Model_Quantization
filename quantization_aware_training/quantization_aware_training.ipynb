{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantization_aware_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeS0c5vYr327",
        "colab_type": "code",
        "outputId": "88069220-8258-4228-a376-28abffe2bb1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# google colab setup\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = '/content/drive/My Drive/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUUu4WCwZLo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b31581d5-204b-44e5-d843-c8aa6a6b7af3"
      },
      "source": [
        "# imports and load the MNIST data\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "(train_data, train_labels), (eval_data, eval_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = (train_data.astype('float32') / 255.0).reshape(-1,28,28,1)\n",
        "eval_data = (eval_data.astype('float32') / 255.0).reshape(-1,28,28,1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhXJ2J7VsBJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build tf.keras model\n",
        "\n",
        "def build_keras_model():\n",
        "    return tf.keras.models.Sequential([\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters = 32, kernel_size=(3,3), activation=tf.nn.relu, padding='same', input_shape=(28,28,1)),\n",
        "        tf.keras.layers.BatchNormalization(fused=False),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), activation=tf.nn.relu, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(fused=False),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters = 64, kernel_size=(3,3), activation=tf.nn.relu, padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(fused=False),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNgp3x2EsGk0",
        "colab_type": "code",
        "outputId": "9b33c28f-ef95-4e4d-99ee-a62a369857db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# train the model, quantization-aware training (finetuning) after $[quant_delay] steps\n",
        "\n",
        "train_batch_size = 50\n",
        "train_batch_number = train_data.shape[0]\n",
        "quant_delay_epoch = 1\n",
        "\n",
        "train_graph = tf.Graph()\n",
        "train_sess = tf.Session(graph=train_graph)\n",
        "\n",
        "tf.keras.backend.set_session(train_sess)\n",
        "with train_graph.as_default():\n",
        "    train_model = build_keras_model()\n",
        "\n",
        "    tf.contrib.quantize.create_training_graph(input_graph=train_graph, quant_delay=int(train_batch_number / train_batch_size * quant_delay_epoch))\n",
        "\n",
        "    train_sess.run(tf.global_variables_initializer())\t \n",
        "\n",
        "    train_model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print('\\n------ Train ------\\n')\n",
        "    train_model.fit(train_data, train_labels, batch_size = train_batch_size, epochs=quant_delay_epoch * 2)\n",
        "\n",
        "    print('\\n------ Test ------\\n')\n",
        "    loss, acc = train_model.evaluate(eval_data, eval_labels)\n",
        "\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(train_sess, '/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/checkpoints')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_1/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization_1/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_2/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization_2/batchnorm/add_1\n",
            "\n",
            "------ Train ------\n",
            "\n",
            "Train on 60000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 31s 517us/sample - loss: 0.0992 - acc: 0.9698\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 29s 491us/sample - loss: 0.0421 - acc: 0.9869\n",
            "\n",
            "------ Test ------\n",
            "\n",
            "10000/10000 [==============================] - 4s 366us/sample - loss: 0.0384 - acc: 0.9887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5izkzPbCbJL",
        "colab_type": "code",
        "outputId": "707fb5dd-2baf-4c09-9b54-4578410b9e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# save the frozen graph\n",
        "\n",
        "eval_graph = tf.Graph()\n",
        "eval_sess = tf.Session(graph=eval_graph)\n",
        "\n",
        "tf.keras.backend.set_session(eval_sess)\n",
        "\n",
        "with eval_graph.as_default():\n",
        "\ttf.keras.backend.set_learning_phase(0)\n",
        "\teval_model = build_keras_model()\n",
        "\ttf.contrib.quantize.create_eval_graph(input_graph=eval_graph)\n",
        "\teval_graph_def = eval_graph.as_graph_def()\n",
        "\tsaver = tf.train.Saver()\n",
        "\tsaver.restore(eval_sess, '/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/checkpoints')\n",
        "    \n",
        "\tfrozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
        "\t\teval_sess,\n",
        "\t\teval_graph_def,\n",
        "\t\t[eval_model.output.op.name]\n",
        "\t)\n",
        "\n",
        "\twith open('/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/frozen_graph.pb', 'wb') as f:\n",
        "\t\tf.write(frozen_graph_def.SerializeToString())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_1/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization_1/batchnorm/add_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_Mul_quant after batch_normalization_2/batchnorm/mul_1\n",
            "INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after batch_normalization_2/batchnorm/add_1\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/checkpoints\n",
            "WARNING:tensorflow:From <ipython-input-5-e3333ed87dac>:18: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 54 variables.\n",
            "INFO:tensorflow:Converted 54 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiYj0Hnz9mL_",
        "colab_type": "code",
        "outputId": "0e07b8b4-f420-4de6-8ec6-bfa275761d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# convert to quantized tf.lite model\n",
        "\n",
        "input_max = np.max(train_data)\n",
        "input_min = np.min(train_data)\n",
        "converter_std = 255 / (input_max - input_min)\n",
        "converter_mean = -(input_min * converter_std)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph('/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/frozen_graph.pb',\n",
        "                                                     ['conv2d_input'],\n",
        "                                                     ['dense_1/Softmax'])\n",
        "converter.inference_type = tf.uint8\n",
        "converter.quantized_input_stats = {'conv2d_input':(converter_mean, converter_std)}\n",
        "#converter.default_ranges_stats = (0,1)\n",
        "tflite_model = converter.convert()\n",
        "open('/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/quantized_model.tflite', 'wb').write(tflite_model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264048"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zmMeA1xtKqa",
        "colab_type": "code",
        "outputId": "49380960-1a67-4a66-ada6-72260489ab28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the quantized tf.lite model and test\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path='/content/drive/My Drive/Colab Notebooks/quantization_github/quantization_aware_training_model/quantized_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "quantize_eval_data = np.array(eval_data * 255, dtype = np.uint8)\n",
        "acc = 0\n",
        "\n",
        "for i in range(quantize_eval_data.shape[0]):\n",
        "\tquantize_image = quantize_eval_data[i]\n",
        "\tquantize_image = quantize_image.reshape(1,28,28,1)\n",
        "\n",
        "\tinterpreter.set_tensor(input_details[0]['index'], quantize_image)\n",
        "\tinterpreter.invoke()\n",
        "\tprediction = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "\tif (eval_labels[i]) == np.argmax(prediction):\n",
        "\t\tacc += 1\n",
        "\n",
        "print('Quantization-aware training (finetuning) accuracy: ' + str(acc / len(eval_data)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantization-aware training (finetuning) accuracy: 0.9886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoZNBU1liFma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "7b91d042-bf03-45e7-fda9-df042545e613"
      },
      "source": [
        "# check the tensor data type\n",
        "\n",
        "tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "for i in tensor_details:\n",
        "    print(i['dtype'], i['name'], i['index'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.uint8'> batch_normalization/batchnorm/add_1 0\n",
            "<class 'numpy.uint8'> batch_normalization/batchnorm/mul 1\n",
            "<class 'numpy.uint8'> batch_normalization/batchnorm/mul_1 2\n",
            "<class 'numpy.uint8'> batch_normalization/batchnorm/sub 3\n",
            "<class 'numpy.uint8'> batch_normalization_1/batchnorm/add_1 4\n",
            "<class 'numpy.uint8'> batch_normalization_1/batchnorm/mul 5\n",
            "<class 'numpy.uint8'> batch_normalization_1/batchnorm/mul_1 6\n",
            "<class 'numpy.uint8'> batch_normalization_1/batchnorm/sub 7\n",
            "<class 'numpy.uint8'> batch_normalization_2/batchnorm/add_1 8\n",
            "<class 'numpy.uint8'> batch_normalization_2/batchnorm/mul 9\n",
            "<class 'numpy.uint8'> batch_normalization_2/batchnorm/mul_1 10\n",
            "<class 'numpy.uint8'> batch_normalization_2/batchnorm/sub 11\n",
            "<class 'numpy.int32'> conv2d/Conv2D_bias 12\n",
            "<class 'numpy.uint8'> conv2d/Relu 13\n",
            "<class 'numpy.uint8'> conv2d/weights_quant/FakeQuantWithMinMaxVars 14\n",
            "<class 'numpy.int32'> conv2d_1/Conv2D_bias 15\n",
            "<class 'numpy.uint8'> conv2d_1/Relu 16\n",
            "<class 'numpy.uint8'> conv2d_1/weights_quant/FakeQuantWithMinMaxVars 17\n",
            "<class 'numpy.int32'> conv2d_2/Conv2D_bias 18\n",
            "<class 'numpy.uint8'> conv2d_2/Relu 19\n",
            "<class 'numpy.uint8'> conv2d_2/weights_quant/FakeQuantWithMinMaxVars 20\n",
            "<class 'numpy.uint8'> conv2d_input 21\n",
            "<class 'numpy.int32'> dense/MatMul_bias 22\n",
            "<class 'numpy.uint8'> dense/Relu 23\n",
            "<class 'numpy.uint8'> dense/weights_quant/FakeQuantWithMinMaxVars/transpose 24\n",
            "<class 'numpy.uint8'> dense_1/BiasAdd 25\n",
            "<class 'numpy.int32'> dense_1/MatMul_bias 26\n",
            "<class 'numpy.uint8'> dense_1/Softmax 27\n",
            "<class 'numpy.uint8'> dense_1/weights_quant/FakeQuantWithMinMaxVars/transpose 28\n",
            "<class 'numpy.uint8'> max_pooling2d/MaxPool 29\n",
            "<class 'numpy.uint8'> max_pooling2d_1/MaxPool 30\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}